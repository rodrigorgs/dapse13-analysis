\Name{Testing Phase} \label{pat:phase}

\Problem

  Identify testing phases in the software development life cycle.

\Context

  Before a new version is shipped to final users, it is common to test new features and bug fixes. In some projects, most of the testing effort is concentrated on a well-defined testing phase, that precedes the release of the next version of the software. 

  In a bug tracking system, testing efforts are recorded as bug status changes, from {\tt RESOLVED} to {\tt VERIFIED}. Testing phases, therefore,  show up as a relatively large number of verifications comprised in a relatively short period.

  Failing to recognize testing phases mislead analyses. For example, if most bugs are verified during a testing phase, then measuring the time from {\tt RESOLVED} to {\tt VERIFIED} does not measure verification effort. Instead, it reflects how early a bug was resolved with respect to the next testing phase.

\Solution

  \emph{Solution 1}. Select verifications, i.e., changes that set the bug status to {\tt VERIFIED}. Then, plot the accumulated number of verifications over time using a line chart. If you know the software release dates, highlight them in the chart with vertical lines. Although the chart is monotonically increasing, some portions may exhibit a steeper ascent, that represents a period with high verification activity. Such periods probably are testing phases, particularly if they precede a release date.

  \emph{Solution 2}. Select verifications, i.e., changes that set the bug status to {\tt VERIFIED}. 
  %If there are two or more verifications at the exact same time, choose only one. 
  Then, apply Kleinberg's algorithm~\cite{Kleinberg2002} to verification times in order to detect bursts, i.e., periods of intense verification activity. 

  The algorithm is based on a Markov model and outputs a hierarchical burst structure. The first level comprises the entire period; the second level contains bursts in the period; the third level, bursts within second-level bursts, and so on. In the data we analyzed, second-level bursts spanned a few days, which seems right for a testing phase, while higher level bursts tended to span a few hours.

\Discussion

  The first solution is suitable for visual exploration of the data. If the data set is too large, however, it becomes difficult to visualize. The second solution is objective, though computationally expensive.

  %There is a third solution, not discussed here: use Kleinberg's algorithm~\cite{Kleinberg2002} to detect bursts of verification activity. It uses a Markov model and is more computationally intensive. The algorithm is implemented in a R package called {\tt bursts}.

  Be suspicious if the number of verifications per day is too high (e.g., above 50). Such verifications may be the result of a mass verification, when multiple bug reports are simultaneously updated in order to tidy the bug tracking system~\cite{Souza2013a}.

  Some teams have dedicated quality engineers that are responsible for testing. Well-defined testing phases are less common in such teams, because quality engineers constantly test features and bug fixes, and therefore do not need to switch between programming and testing activities. 

  %To determine if this is the case, analyze the individual verifications on that day. If most of them were performed by the same person, a few seconds or minutes apart from each other, then they are likely the result of a mass verification.

\Example

<<echo=FALSE,results=hide>>=
changes <- readRDS("../data/eclipse-platform-changes.rds")
releases <- readRDS("../data/eclipse-platform-releases.rds")
@

  The first solution was used by Souza and Chavez~\cite{Souza2012} (see Figure 2 in their paper). The following R code shows how to apply the solution to  Eclipse/Platform. Only a subset of the data is used, otherwise testing phases would be difficult to visualize. Assume {\tt releases\$date} is a vector with release dates.

<<results=hide>>=
ver <- subset(changes, 
	field == "bug_status" 
    & new.value == "VERIFIED")
ver <- ver[order(ver$time), ]
ver$n.changes <- 1:nrow(ver)
ver <- subset(ver, 
	time >= as.POSIXct("2009-06-10")
    & time < as.POSIXct("2010-06-09"))
with(ver, plot(n.changes ~ time, type="l"))
abline(v=releases$date, lty=2)
@

<<figphases,echo=FALSE,include=FALSE>>=
library(zoo)
par(mar=c(4.5,4,1,1)+0.1)
with(ver, plot(n.changes ~ time, type="l", xaxt="n", xlab=""))
abline(v=releases$date, lty=2)
ticks <- seq(min(ver$time), max(ver$time), by = "months")
labels <- format(as.yearmon(ticks), "%Y-%m")
axis(1, at = ticks, labels=labels, las=2)
@

  The result is shown in Figure~\ref{fig:phases}. Notice how verification activity (steep ascents) is concentrated just before release dates (dashed vertical lines), suggesting there are well-defined testing phases in Eclipse/Platform.

\begin{figure}[!t]
\centering
<<fig=TRUE,echo=FALSE,width=6,height=4.0>>=
<<figphases>>
@
  \caption{Accumulated number of verifications over time.}
  \label{fig:phases}
\end{figure}

<<echo=FALSE,results=hide>>=
nrows <- 5
@

  The following R code shows how to apply the second solution, using Kleinberg's algorithm and taking second-level bursts. Then, we count the number of verifications, total and per day, in each burst. The variable {\tt ver} is reused from the previous snippet of code. The first \Sexpr{nrows} bursts are shown in Table~\ref{tab:bursts}.

<<>>=
library(bursts)
k <- kleinberg(unique(ver$time))
bursts <- subset(k, level == 2)

# Num. of verifications (total and per day average)
bursts$count <- apply(bursts, 1, function(x) 
  sum(ver$time > as.POSIXct(x["start"]) 
      & ver$time < as.POSIXct(x["end"])))
days <- as.Date(bursts$end) - as.Date(bursts$start)
days <- days + 1
bursts$per.day <- bursts$count %/% as.numeric(days)
@

<<echo=FALSE,results=tex>>=
library(xtable)
h <- head(bursts, nrows)
h$level <- NULL
h$start <- as.character(h$start)
h$end <- as.character(h$end)
h$per.day <- as.integer(h$per.day)
x <- xtable(h, 
  caption="Periods with intense verification activity (sample).",
  label="tab:bursts")
print(x,
  include.rownames=FALSE,
  caption.placement="top",
  table.placement="!t")
@

\RelatedPatterns

  Before applying this pattern, use the \emph{Look Out For Mass Updates} pattern~\cite{Souza2013a} to remove mass verifications from the data. Periods which include mass verifications can be confused with testing phases.

  Use the \emph{Fixers and Verifiers} pattern (Section ~\ref{pat:subjects}) to assess if the project has a quality team. The existence of such teams may explain the absence of a testing phase.
